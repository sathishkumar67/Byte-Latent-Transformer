{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1fdaa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Byte-Latent-Transformer'...\n",
      "remote: Enumerating objects: 162, done.\u001b[K\n",
      "remote: Counting objects: 100% (162/162), done.\u001b[K\n",
      "remote: Compressing objects: 100% (114/114), done.\u001b[K\n",
      "remote: Total 162 (delta 91), reused 107 (delta 43), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (162/162), 51.19 KiB | 5.69 MiB/s, done.\n",
      "Resolving deltas: 100% (91/91), done.\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1.2\n",
      "    Uninstalling pip-24.1.2:\n",
      "      Successfully uninstalled pip-24.1.2\n",
      "Successfully installed pip-25.2\n",
      "Collecting lightning==2.5.3 (from -r requirements.txt (line 1))\n",
      "  Downloading lightning-2.5.3-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: PyYAML<8.0,>5.4 in /usr/local/lib/python3.11/dist-packages (from lightning==2.5.3->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: fsspec<2027.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning==2.5.3->-r requirements.txt (line 1)) (2025.5.1)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning==2.5.3->-r requirements.txt (line 1)) (0.14.3)\n",
      "Requirement already satisfied: packaging<27.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning==2.5.3->-r requirements.txt (line 1)) (25.0)\n",
      "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from lightning==2.5.3->-r requirements.txt (line 1)) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchmetrics<3.0,>0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning==2.5.3->-r requirements.txt (line 1)) (1.7.3)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning==2.5.3->-r requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<6.0,>4.5.0 in /usr/local/lib/python3.11/dist-packages (from lightning==2.5.3->-r requirements.txt (line 1)) (4.14.0)\n",
      "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning==2.5.3->-r requirements.txt (line 1)) (2.5.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2027.0,>=2022.5.0->lightning==2.5.3->-r requirements.txt (line 1)) (3.12.13)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning==2.5.3->-r requirements.txt (line 1)) (75.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.5.3->-r requirements.txt (line 1)) (3.18.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.5.3->-r requirements.txt (line 1)) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.5.3->-r requirements.txt (line 1)) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning==2.5.3->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning==2.5.3->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning==2.5.3->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<4.0,>=2.1.0->lightning==2.5.3->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<4.0,>=2.1.0->lightning==2.5.3->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<4.0,>=2.1.0->lightning==2.5.3->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<4.0,>=2.1.0->lightning==2.5.3->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<4.0,>=2.1.0->lightning==2.5.3->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<4.0,>=2.1.0->lightning==2.5.3->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.5.3->-r requirements.txt (line 1)) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.5.3->-r requirements.txt (line 1)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.5.3->-r requirements.txt (line 1)) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning==2.5.3->-r requirements.txt (line 1))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.5.3->-r requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning==2.5.3->-r requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning==2.5.3->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics<3.0,>0.7.0->lightning==2.5.3->-r requirements.txt (line 1)) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning==2.5.3->-r requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning==2.5.3->-r requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning==2.5.3->-r requirements.txt (line 1)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning==2.5.3->-r requirements.txt (line 1)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning==2.5.3->-r requirements.txt (line 1)) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning==2.5.3->-r requirements.txt (line 1)) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning==2.5.3->-r requirements.txt (line 1)) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2027.0,>=2022.5.0->lightning==2.5.3->-r requirements.txt (line 1)) (3.10)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>0.7.0->lightning==2.5.3->-r requirements.txt (line 1)) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>0.7.0->lightning==2.5.3->-r requirements.txt (line 1)) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>0.7.0->lightning==2.5.3->-r requirements.txt (line 1)) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>0.7.0->lightning==2.5.3->-r requirements.txt (line 1)) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>0.7.0->lightning==2.5.3->-r requirements.txt (line 1)) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>0.7.0->lightning==2.5.3->-r requirements.txt (line 1)) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning==2.5.3->-r requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20.0->torchmetrics<3.0,>0.7.0->lightning==2.5.3->-r requirements.txt (line 1)) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20.0->torchmetrics<3.0,>0.7.0->lightning==2.5.3->-r requirements.txt (line 1)) (2022.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>1.20.0->torchmetrics<3.0,>0.7.0->lightning==2.5.3->-r requirements.txt (line 1)) (2024.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>1.20.0->torchmetrics<3.0,>0.7.0->lightning==2.5.3->-r requirements.txt (line 1)) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>1.20.0->torchmetrics<3.0,>0.7.0->lightning==2.5.3->-r requirements.txt (line 1)) (2024.2.0)\n",
      "Downloading lightning-2.5.3-py3-none-any.whl (824 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m824.2/824.2 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m  \u001b[33m0:00:06\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, lightning\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82/11\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 0/11\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.6.820m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.6.82:0m \u001b[32m 0/11\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.6.82笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 1/11\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 1/11\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.2.3.61笏≫煤\u001b[0m \u001b[32m 1/11\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.2.3.61:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 1/11\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 2/11\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 2/11\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82笏―u001b[0m \u001b[32m 3/11\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 3/11\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82[0m \u001b[32m 3/11\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 3/11\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82笏≫煤笏―u001b[0m \u001b[32m 4/11\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 4/11\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82笏≫煤笏≫煤笏―u001b[0m \u001b[32m 4/11\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 4/11\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82[0m \u001b[32m 4/11\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 4/11\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82笏≫煤笏≫煤笏―u001b[0m \u001b[32m 5/11\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu1290m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 5/11\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.5.3.2笏≫煤\u001b[0m \u001b[32m 5/11\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.5.3.2:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 5/11\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 6/11\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 6/11\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\u001b[0m \u001b[32m 6/11\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.1.3:笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 6/11\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 7/11\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12m笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 7/11\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.3.0.75笏≫煤笏―u001b[0m \u001b[32m 7/11\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.3.0.75:[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 7/11\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m 8/11\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu120m笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 8/11\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.6.3.83[0m \u001b[32m 8/11\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.6.3.83:[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m 8/11\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83笏≫煤笏≫煤笏―u001b[0m \u001b[32m 9/11\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m11/11\u001b[0m [lightning]11\u001b[0m [lightning]olver-cu12]\n",
      "\u001b[1A\u001b[2KSuccessfully installed lightning-2.5.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "# clone the BLT repository\n",
    "!git clone https://github.com/sathishkumar67/Byte-Latent-Transformer.git\n",
    "# move the files to the current directory\n",
    "!mv /kaggle/working/Byte-Latent-Transformer/* /kaggle/working/\n",
    "# upgrade pip\n",
    "!pip install --upgrade pip\n",
    "# install latest version pytorch\n",
    "# install the required packages\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c516d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import shutil\n",
    "\n",
    "# # Get current working directory\n",
    "# current_dir = os.getcwd()\n",
    "\n",
    "# for item in os.listdir(current_dir):\n",
    "#     item_path = os.path.join(current_dir, item)\n",
    "#     try:\n",
    "#         if os.path.isfile(item_path) or os.path.islink(item_path):\n",
    "#             os.remove(item_path)  # remove file or symlink\n",
    "#         elif os.path.isdir(item_path):\n",
    "#             shutil.rmtree(item_path)  # remove folder and its contents\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to delete {item_path}. Reason: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd0179f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import lightning as L\n",
    "from lightning.pytorch import Trainer\n",
    "from BLT.entropy import EntropyModel, EntropyConfig\n",
    "from BLT.dataset import TokenDataset\n",
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0729ca30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123742aa86ad450fbfdf8dfbb1f3a25e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "wikipedia_512_pretraining/tokenized_text(窶ｦ):   0%|          | 0.00/146M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# download the tokenized text\n",
    "hf_hub_download(repo_id=\"pt-sk/Text_Bytes_Tokens\",\n",
    "                filename=\"wikipedia_512_pretraining/tokenized_text1.npy\",\n",
    "                repo_type=\"dataset\",\n",
    "                local_dir=\"/kaggle/working/\")\n",
    "\n",
    "# load the tokenized text\n",
    "tokens = np.load(\"/kaggle/working/wikipedia_512_pretraining/tokenized_text1.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e53995ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the model: 35.800064M\n"
     ]
    }
   ],
   "source": [
    "# Initialize model and config\n",
    "config = EntropyConfig()\n",
    "model = EntropyModel(config)\n",
    "\n",
    "# count the number of parameters in the model\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters in the model: {num_params/1e6}M\")\n",
    "\n",
    "def configure_optimizer(model: nn.Module) -> torch.optim.Optimizer:\n",
    "        # start with all of the candidate parameters (that require grad)\n",
    "        param_dict = {pn: p for pn, p in model.named_parameters()}\n",
    "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
    "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
    "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
    "        decay_params = [p for _, p in param_dict.items() if p.dim() >= 2]\n",
    "        nodecay_params = [p for _, p in param_dict.items() if p.dim() < 2]\n",
    "\n",
    "        # Create AdamW optimizer and use the fused version if available\n",
    "        return torch.optim.AdamW([{'params': decay_params, 'weight_decay': 0.1},\n",
    "                                {'params': nodecay_params, 'weight_decay': 0.0}],\n",
    "                                lr=0.0001,\n",
    "                                betas=(0.9, 0.999),\n",
    "                                eps=1e-8,\n",
    "                                fused=True)\n",
    "\n",
    "optimizer = configure_optimizer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4667d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTWrapper(L.LightningModule):\n",
    "    def __init__(self, config: EntropyConfig, model: EntropyModel) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.optimizer = self.configure_optimizers()\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        self.model.train()\n",
    "        optimizer = self.optimizers()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inputs, targets = batch\n",
    "        _, loss = self.model(inputs, targets)\n",
    "        self.log(\"Train_Loss\", loss, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = configure_optimizer(self.model)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0aa6f92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TokenDataset(block_size=2048, input_ids=tokens)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=8)\n",
    "\n",
    "model_wrapper = GPTWrapper(config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "152bb1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: 汳｡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(max_epochs=1,\n",
    "                  accelerator=\"cuda\",\n",
    "                  devices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad33c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO: \n",
      "  | Name  | Type         | Params | Mode \n",
      "-----------------------------------------------\n",
      "0 | model | EntropyModel | 35.8 M | train\n",
      "-----------------------------------------------\n",
      "35.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "35.8 M    Total params\n",
      "143.200   Total estimated model params size (MB)\n",
      "118       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3f309844494dd5951e7e56d9c81d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model_wrapper, dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
